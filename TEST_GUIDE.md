# 動的ツール管理システム テストガイド

このガイドでは、実装した動的ツール管理システムの包括的なテストを行います。

## テスト環境の準備

### 1. 必要な設定

#### バックエンド (.env)
```bash
# LLMプロバイダーのAPIキーを設定
OPENAI_API_KEY=your_openai_api_key
# または
ANTHROPIC_API_KEY=your_anthropic_api_key
# または
GOOGLE_API_KEY=your_google_api_key

# データベース
DATABASE_URL=sqlite:///./app/ai_agent_team.db

# 暗号化キー（既存のものを使用）
ENCRYPTION_KEY=your_existing_encryption_key
```

### 2. サーバーの起動

#### バックエンド
```bash
cd backend
source venv/bin/activate
python run.py
```

#### フロントエンド
```bash
cd frontend
npm run dev
```

## テストシナリオ

### Phase 1: 基本機能のテスト

#### Test 1.1: LLMプロバイダーの設定
1. ブラウザで `http://localhost:5173` を開く
2. 「設定」タブに移動
3. 「新しいLLM設定を追加」をクリック
4. プロバイダーを選択（例: OpenAI）
5. APIキーを入力
6. モデルを選択（例: gpt-4o-mini）
7. 「保存」をクリック
8. 「接続テスト」をクリックして動作確認

**期待される結果:**
- 設定が正常に保存される
- 接続テストが成功する
- 設定一覧に表示される

#### Test 1.2: エージェントの作成
1. 「エージェント」タブに移動
2. 「新規作成」をクリック
3. 以下を入力:
   - 名前: "テストエージェント"
   - 役割: "データ分析担当"
   - 説明: "データ分析とレポート作成を行うエージェント"
   - LLMプロバイダー: 設定したプロバイダーを選択
   - モデル: 利用可能なモデルから選択
4. 「作成」をクリック

**期待される結果:**
- エージェントが正常に作成される
- エージェント一覧に表示される
- ステータスが「アクティブ」になる

### Phase 2: 動的ツール生成のテスト

#### Test 2.1: AIによるツール生成
1. 「ツール」タブに移動
2. 「AIでツールを生成」をクリック
3. 以下を入力:
   ```
   ツールの説明: 
   株価情報を取得するツールを作成してください。
   yfinanceライブラリを使用して、指定された銘柄コードの現在の株価、
   前日比、出来高を取得できるようにしてください。
   ```
4. LLMプロバイダーを選択
5. 「生成」をクリック
6. 生成されたコードを確認
7. 「登録」をクリック

**期待される結果:**
- ツールコードが自動生成される
- yfinanceの依存関係が自動インストールされる
- ツールが正常に登録される
- ツール一覧に表示される

#### Test 2.2: 手動ツール登録
1. 「ツール」タブで「手動で登録」をクリック
2. 以下を入力:
   - ツール名: `weather_tool`
   - 説明: "天気情報を取得するツール"
   - カテゴリ: `api`
   - コード:
   ```python
   from langchain_core.tools import BaseTool
   from typing import Optional, Type
   from pydantic import BaseModel, Field
   import requests
   
   class WeatherInput(BaseModel):
       city: str = Field(description="都市名（例: Tokyo, New York）")
   
   class WeatherTool(BaseTool):
       name = "weather_tool"
       description = "指定された都市の天気情報を取得します"
       args_schema: Type[BaseModel] = WeatherInput
       
       def _run(self, city: str) -> str:
           # 簡易的な実装（実際にはAPIキーが必要）
           return f"{city}の天気: 晴れ、気温: 25度"
       
       async def _arun(self, city: str) -> str:
           return self._run(city)
   ```
3. 「登録」をクリック

**期待される結果:**
- ツールが正常に登録される
- ツール一覧に表示される

### Phase 3: タスク分析機能のテスト

#### Test 3.1: タスク作成とツール推奨
1. 「タスク」タブに移動
2. 「新規作成」をクリック
3. 以下を入力:
   - タイトル: "株価レポート作成"
   - 説明: 
   ```
   AppleとMicrosoftの株価情報を取得して、
   過去1週間の価格推移をまとめたレポートを作成してください。
   ```
   - 優先度: 高
   - モード: 手動
   - 担当エージェント: 作成したエージェントを選択
4. 「タスクを分析してツールを推奨」をクリック
5. 推奨されたツールを確認
6. 必要なツールを選択
7. 「作成」をクリック

**期待される結果:**
- タスクが分析される
- 株価取得ツールが推奨される
- 選択したツールがタスクに関連付けられる
- タスクが作成される

#### Test 3.2: タスクの実行
1. 作成したタスクの「実行」ボタンをクリック
2. 実行状態を監視
3. 完了後、結果を確認

**期待される結果:**
- タスクが「実行中」になる
- エージェントが推奨ツールを使用してタスクを実行
- Function Callingが正しく動作する
- タスクが「完了」になる
- 結果が表示される

### Phase 4: 複雑なシナリオのテスト

#### Test 4.1: 複数ツールを使用するタスク
1. 新しいタスクを作成:
   - タイトル: "総合レポート作成"
   - 説明:
   ```
   以下の情報を収集してレポートを作成してください:
   1. Appleの株価情報
   2. 東京の天気情報
   3. 最新のテクノロジーニュース（Web検索）
   ```
2. タスク分析を実行
3. 推奨された複数のツールを確認
4. タスクを実行

**期待される結果:**
- 複数のツールが推奨される
- エージェントが適切なツールを選択して使用
- すべての情報が収集される
- 統合されたレポートが生成される

#### Test 4.2: エラーハンドリング
1. 存在しない銘柄コードでタスクを作成
2. タスクを実行
3. エラーメッセージを確認

**期待される結果:**
- エラーが適切にハンドリングされる
- エラーメッセージが表示される
- システムがクラッシュしない

## テストチェックリスト

### 基本機能
- [ ] LLMプロバイダーの設定
- [ ] エージェントの作成
- [ ] エージェントの編集・削除

### ツール管理
- [ ] AIによるツール生成
- [ ] 手動ツール登録
- [ ] ツールの一覧表示
- [ ] ツールの削除
- [ ] 依存関係の自動インストール

### タスク管理
- [ ] タスクの作成
- [ ] タスク分析機能
- [ ] ツール推奨機能
- [ ] タスクの実行
- [ ] タスクのキャンセル
- [ ] タスクの削除

### エージェント実行
- [ ] 単一ツールの使用
- [ ] 複数ツールの使用
- [ ] Function Callingの動作
- [ ] エラーハンドリング
- [ ] 実行ログの記録

### UI/UX
- [ ] レスポンシブデザイン
- [ ] ローディング表示
- [ ] エラーメッセージ表示
- [ ] 成功メッセージ表示

## トラブルシューティング

### よくある問題

#### 1. ツール生成が失敗する
- LLMプロバイダーのAPIキーが正しいか確認
- LLMプロバイダーの接続テストを実行
- バックエンドのログを確認: `backend/logs/app.log`

#### 2. 依存関係のインストールが失敗する
- venv環境が正しくアクティベートされているか確認
- pip が最新版か確認: `pip install --upgrade pip`
- 手動でインストールを試す: `pip install <package_name>`

#### 3. タスク実行が失敗する
- エージェントにLLMプロバイダーが設定されているか確認
- 推奨ツールが正しく登録されているか確認
- エージェントのステータスが「アクティブ」か確認

#### 4. WebSocketエラー
- バックエンドが起動しているか確認
- ポート5000が使用可能か確認
- ブラウザのコンソールでエラーを確認

## パフォーマンステスト

### 1. 大量ツール登録
- 10個以上のツールを登録
- ツール一覧の表示速度を確認
- タスク分析の速度を確認

### 2. 長時間実行タスク
- 複雑なタスクを作成
- 実行時間を測定
- メモリ使用量を監視

### 3. 同時実行
- 複数のタスクを同時に実行
- システムの安定性を確認
- リソース使用量を監視

## 次のステップ

テストが完了したら、以下を実施:

1. **Phase 2の実装**: 実行時の動的ツール追加
2. **Phase 3の実装**: 自動クリーンアップ機能
3. **追加機能**: MCPツール動的登録
4. **最適化**: パフォーマンス改善
5. **ドキュメント**: ユーザーガイドの作成

## レポート

テスト結果を以下の形式で記録:

```markdown
## テスト結果レポート

### 実施日時
YYYY-MM-DD HH:MM

### テスト環境
- OS: 
- Python: 
- Node.js: 
- ブラウザ: 

### テスト結果
| テスト項目 | 結果 | 備考 |
|-----------|------|------|
| LLM設定 | ✅ | - |
| エージェント作成 | ✅ | - |
| ツール生成 | ✅ | - |
| タスク分析 | ✅ | - |
| タスク実行 | ✅ | - |

### 発見された問題
1. 問題の説明
2. 再現手順
3. 期待される動作
4. 実際の動作

### 改善提案
1. 提案内容
2. 優先度
3. 実装方法